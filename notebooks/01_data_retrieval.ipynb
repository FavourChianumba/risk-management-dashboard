{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Management Dashboard - Data Retrieval\n",
    "\n",
    "This notebook demonstrates how to retrieve market data from Yahoo Finance and macroeconomic data from FRED for the risk management dashboard project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import json\n",
    "%pip install pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%pip install seaborn\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "# Configure plot styles\n",
    "# Use modern style naming convention\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')  # For newer versions of matplotlib\n",
    "except:\n",
    "    try:\n",
    "        plt.style.use('seaborn-darkgrid')  # For older versions\n",
    "    except:\n",
    "        print(\"Could not set seaborn style, using default style instead\")\n",
    "\n",
    "# Alternative approach: just use seaborn's built-in styling\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_palette('muted')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up project paths\n",
    "PROJECT_ROOT = Path().resolve().parents[0]\n",
    "CONFIG_DIR = PROJECT_ROOT / \"configs\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "\n",
    "# Make sure raw data directory exists\n",
    "raw_data_dir = DATA_DIR / \"raw\"\n",
    "raw_data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Config directory: {CONFIG_DIR}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data configuration\n",
    "with open(CONFIG_DIR / \"data_config.json\", 'r') as f:\n",
    "    data_config = json.load(f)\n",
    "\n",
    "# Extract configuration parameters\n",
    "config = data_config['data_retrieval']\n",
    "start_date = config['start_date']\n",
    "end_date = config['end_date']\n",
    "\n",
    "# Display configuration\n",
    "print(\"Data Retrieval Configuration:\")\n",
    "print(f\"Start Date: {start_date}\")\n",
    "print(f\"End Date: {end_date}\")\n",
    "print(f\"Lookback Years: {config['lookback_years']}\")\n",
    "\n",
    "# Display indices and indicators\n",
    "print(\"\\nEquity Indices:\")\n",
    "for idx in config['equity_indices']:\n",
    "    print(f\"  - {idx['description']} ({idx['ticker']}): {idx['weight']*100:.1f}%\")\n",
    "\n",
    "print(\"\\nBond Indices:\")\n",
    "for idx in config['bond_indices']:\n",
    "    print(f\"  - {idx['description']} ({idx['ticker']}): {idx['weight']*100:.1f}%\")\n",
    "\n",
    "print(\"\\nMacroeconomic Indicators:\")\n",
    "for idx in config['macro_indicators']:\n",
    "    print(f\"  - {idx['description']} ({idx['series_id']}): {idx['frequency']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "First, let's load the data retrieval configuration from the config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data Retrieval Module\n",
    "\n",
    "Now, let's import the data retrieval functions from our module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to the path\n",
    "import sys\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "%pip install requests \n",
    "\n",
    "# Import data retrieval functions\n",
    "from src.data.retrieve_data import (\n",
    "    load_api_keys,\n",
    "    get_market_data,\n",
    "    get_fred_data,\n",
    "    load_crisis_periods,\n",
    "    get_data_for_date_range\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Market Data\n",
    "\n",
    "Let's retrieve market data for our equity and bond indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get equity and bond tickers\n",
    "equity_tickers = [item['ticker'] for item in config['equity_indices']]\n",
    "bond_tickers = [item['ticker'] for item in config['bond_indices']]\n",
    "all_tickers = equity_tickers + bond_tickers\n",
    "\n",
    "# Retrieve market data\n",
    "try:\n",
    "    print(f\"Retrieving market data for {all_tickers}...\")\n",
    "    market_data = get_market_data(\n",
    "        tickers=all_tickers,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date\n",
    "    )\n",
    "    print(\"Market data retrieved successfully.\")\n",
    "    \n",
    "    # Display the first few rows of the data\n",
    "    print(\"\\nFirst few rows of market data:\")\n",
    "    display(market_data.head())\n",
    "    \n",
    "    # Display data info\n",
    "    print(\"\\nMarket data info:\")\n",
    "    for col in market_data.columns.levels[0]:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving market data: {e}\")\n",
    "    print(\"Attempting to use Yahoo Finance directly...\")\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        \n",
    "        # Map tickers to Yahoo format\n",
    "        ticker_map = {\n",
    "            \"SPX\": \"^GSPC\",  # S&P 500\n",
    "            \"US10YT=RR\": \"^TNX\"  # 10-Year Treasury Yield\n",
    "        }\n",
    "        yahoo_tickers = [ticker_map.get(ticker, ticker) for ticker in all_tickers]\n",
    "        \n",
    "        # Download data\n",
    "        data = yf.download(yahoo_tickers, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        # Save data to CSV\n",
    "        data.to_csv(raw_data_dir / f\"yahoo_data_{dt.datetime.now().strftime('%Y%m%d')}.csv\")\n",
    "        \n",
    "        print(\"Market data retrieved from Yahoo Finance successfully.\")\n",
    "        market_data = data\n",
    "        \n",
    "        # Display the first few rows of the data\n",
    "        print(\"\\nFirst few rows of Yahoo Finance data:\")\n",
    "        display(market_data.head())\n",
    "    except Exception as e2:\n",
    "        print(f\"Error retrieving market data from Yahoo Finance: {e2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Macroeconomic Data\n",
    "\n",
    "Now, let's retrieve macroeconomic data from FRED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get macro indicators\n",
    "macro_indicators = [item['series_id'] for item in config['macro_indicators']]\n",
    "\n",
    "# Retrieve macroeconomic data\n",
    "try:\n",
    "    print(f\"Retrieving macroeconomic data for {macro_indicators}...\")\n",
    "    macro_data = get_fred_data(\n",
    "        series_ids=macro_indicators,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date\n",
    "    )\n",
    "    print(\"Macroeconomic data retrieved successfully.\")\n",
    "    \n",
    "    # Display the first few rows of the data\n",
    "    print(\"\\nFirst few rows of macroeconomic data:\")\n",
    "    display(macro_data.head())\n",
    "    \n",
    "    # Display data info\n",
    "    print(\"\\nMacroeconomic data info:\")\n",
    "    print(f\"Shape: {macro_data.shape}\")\n",
    "    print(f\"Columns: {macro_data.columns.tolist()}\")\n",
    "    print(f\"Date range: {macro_data.index.min()} to {macro_data.index.max()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving macroeconomic data: {e}\")\n",
    "    print(\"Attempting to use pandas_datareader as fallback...\")\n",
    "    \n",
    "    try:\n",
    "        import pandas_datareader as pdr\n",
    "        \n",
    "        # Create empty DataFrame\n",
    "        macro_data = pd.DataFrame()\n",
    "        \n",
    "        # Try to get each series\n",
    "        for series_id in macro_indicators:\n",
    "            try:\n",
    "                series = pdr.get_data_fred(series_id, start=start_date, end=end_date)\n",
    "                macro_data[series_id] = series[series_id]\n",
    "                print(f\"Retrieved {series_id} successfully.\")\n",
    "            except Exception as e_series:\n",
    "                print(f\"Error retrieving {series_id}: {e_series}\")\n",
    "        \n",
    "        if not macro_data.empty:\n",
    "            print(\"Successfully retrieved some macro data with pandas_datareader.\")\n",
    "            display(macro_data.head())\n",
    "        else:\n",
    "            print(\"Failed to retrieve any macro data.\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error using pandas_datareader: {e2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Historical Crisis Periods File\n",
    "\n",
    "Let's create a file with historical crisis periods that will be used for stress testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing crisis periods or create new ones\n",
    "crisis_periods = load_crisis_periods()\n",
    "\n",
    "# Display crisis periods\n",
    "print(\"Loaded Historical Crisis Periods:\")\n",
    "display(crisis_periods)\n",
    "\n",
    "# Calculate duration in days if not already present\n",
    "if 'duration_days' not in crisis_periods.columns:\n",
    "    crisis_periods['duration_days'] = (crisis_periods['end_date'] - crisis_periods['start_date']).dt.days\n",
    "    # Save updated data\n",
    "    crisis_file = DATA_DIR / \"external\" / \"crisis_periods.csv\"\n",
    "    crisis_periods.to_csv(crisis_file, index=False)\n",
    "    print(f\"Added duration_days and saved to {crisis_file}\")\n",
    "\n",
    "# Ask if user wants to add more crisis periods\n",
    "add_more = input(\"Do you want to add more crisis periods? (yes/no): \")\n",
    "\n",
    "if add_more.lower() == 'yes':\n",
    "    new_periods = []\n",
    "    \n",
    "    while True:\n",
    "        name = input(\"Enter crisis name (or 'done' to finish): \")\n",
    "        if name.lower() == 'done':\n",
    "            break\n",
    "            \n",
    "        start_date = input(\"Enter start date (YYYY-MM-DD): \")\n",
    "        end_date = input(\"Enter end date (YYYY-MM-DD): \")\n",
    "        description = input(\"Enter description: \")\n",
    "        \n",
    "        new_periods.append({\n",
    "            'name': name,\n",
    "            'start_date': start_date,\n",
    "            'end_date': end_date,\n",
    "            'description': description\n",
    "        })\n",
    "    \n",
    "    if new_periods:\n",
    "        # Create DataFrame\n",
    "        new_df = pd.DataFrame(new_periods)\n",
    "        \n",
    "        # Convert dates to datetime\n",
    "        new_df['start_date'] = pd.to_datetime(new_df['start_date'])\n",
    "        new_df['end_date'] = pd.to_datetime(new_df['end_date'])\n",
    "        \n",
    "        # Calculate duration in days\n",
    "        new_df['duration_days'] = (new_df['end_date'] - new_df['start_date']).dt.days\n",
    "        \n",
    "        # Append to existing data\n",
    "        crisis_periods = pd.concat([crisis_periods, new_df], ignore_index=True)\n",
    "        \n",
    "        # Save updated data\n",
    "        crisis_file = DATA_DIR / \"external\" / \"crisis_periods.csv\"\n",
    "        crisis_periods.to_csv(crisis_file, index=False)\n",
    "        \n",
    "        print(f\"Added {len(new_periods)} new crisis periods.\")\n",
    "        display(crisis_periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Let's create some basic visualizations of the retrieved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot market data\n",
    "if 'market_data' in locals():\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Extract closing prices\n",
    "    if isinstance(market_data.columns, pd.MultiIndex) and 'TRDPRC_1' in market_data.columns.levels[0]:\n",
    "        # For structured data\n",
    "        prices = market_data['TRDPRC_1']\n",
    "    elif isinstance(market_data.columns, pd.MultiIndex) and 'Adj Close' in market_data.columns.levels[0]:\n",
    "        # For Yahoo Finance data\n",
    "        prices = market_data['Adj Close']\n",
    "    else:\n",
    "        # For flat column structure\n",
    "        prices = market_data\n",
    "        \n",
    "    # Normalize prices to 100 at the start\n",
    "    normalized_prices = prices / prices.iloc[0] * 100\n",
    "    \n",
    "    # Plot normalized prices\n",
    "    normalized_prices.plot(ax=plt.gca())\n",
    "    \n",
    "    plt.title('Normalized Asset Prices (Base = 100)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Normalized Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate returns\n",
    "    returns = prices.pct_change().dropna()\n",
    "    \n",
    "    # Plot returns distributions\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    for col in returns.columns:\n",
    "        sns.kdeplot(returns[col], label=col)\n",
    "    \n",
    "    plt.title('Return Distributions')\n",
    "    plt.xlabel('Daily Return')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot macroeconomic data\n",
    "if 'macro_data' in locals() and not macro_data.empty:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Plot each macro indicator on its own subplot\n",
    "    fig, axes = plt.subplots(len(macro_data.columns), 1, figsize=(14, 4*len(macro_data.columns)), sharex=True)\n",
    "    \n",
    "    # Handle single axis case\n",
    "    if len(macro_data.columns) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, col in enumerate(macro_data.columns):\n",
    "        # Try to get the description from the config\n",
    "        try:\n",
    "            description = next((item['description'] for item in config['macro_indicators'] if item['series_id'] == col), col)\n",
    "        except:\n",
    "            description = col\n",
    "        \n",
    "        # Plot the data\n",
    "        macro_data[col].plot(ax=axes[i])\n",
    "        axes[i].set_title(f\"{description} ({col})\")\n",
    "        axes[i].grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight Crisis Periods\n",
    "\n",
    "Let's visualize the market data with crisis periods highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot market data with crisis periods highlighted\n",
    "if 'market_data' in locals() and 'crisis_periods' in locals():\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Extract closing prices\n",
    "    if isinstance(market_data.columns, pd.MultiIndex) and 'TRDPRC_1' in market_data.columns.levels[0]:\n",
    "        # For structured data\n",
    "        prices = market_data['TRDPRC_1']\n",
    "    elif isinstance(market_data.columns, pd.MultiIndex) and 'Adj Close' in market_data.columns.levels[0]:\n",
    "        # For Yahoo Finance data\n",
    "        prices = market_data['Adj Close']\n",
    "    else:\n",
    "        # For flat column structure\n",
    "        prices = market_data\n",
    "    \n",
    "    # Select the first equity index\n",
    "    equity_symbol = equity_tickers[0]\n",
    "    \n",
    "    # Map to Yahoo symbol if needed\n",
    "    if equity_symbol == \"SPX\" and \"^GSPC\" in prices.columns:\n",
    "        equity_symbol = \"^GSPC\"\n",
    "    \n",
    "    if equity_symbol in prices.columns:\n",
    "        # Normalize prices to 100 at the start\n",
    "        equity_prices = prices[equity_symbol]\n",
    "        normalized_prices = equity_prices / equity_prices.iloc[0] * 100\n",
    "        \n",
    "        # Plot normalized prices\n",
    "        normalized_prices.plot(ax=plt.gca())\n",
    "        \n",
    "        # Highlight crisis periods\n",
    "        min_price = normalized_prices.min()\n",
    "        max_price = normalized_prices.max()\n",
    "        padding = (max_price - min_price) * 0.05\n",
    "        \n",
    "        for _, crisis in crisis_periods.iterrows():\n",
    "            if crisis['start_date'] < normalized_prices.index.max() and crisis['end_date'] > normalized_prices.index.min():\n",
    "                plt.axvspan(\n",
    "                    crisis['start_date'],\n",
    "                    crisis['end_date'],\n",
    "                    alpha=0.2,\n",
    "                    color='red',\n",
    "                    label=crisis['name'] if 'current_crisis' not in locals() else \"\"\n",
    "                )\n",
    "                \n",
    "                # Add text label\n",
    "                plt.text(\n",
    "                    crisis['start_date'] + (crisis['end_date'] - crisis['start_date']) / 2,\n",
    "                    max_price + padding,\n",
    "                    crisis['name'],\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    fontsize=10,\n",
    "                    rotation=45\n",
    "                )\n",
    "                \n",
    "                # Track that we've added this crisis\n",
    "                locals()['current_crisis'] = crisis['name']\n",
    "        \n",
    "        plt.title(f'Normalized {equity_symbol} Price with Crisis Periods')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Normalized Price')\n",
    "        plt.ylim(min_price - padding, max_price + padding*3)\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the All-in-One Data Retrieval Function\n",
    "\n",
    "The module provides a convenience function to get all data in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all data in one call using the convenience function\n",
    "try:\n",
    "    print(f\"Retrieving all data for period: {start_date} to {end_date}\")\n",
    "    all_market_data, all_macro_data, all_crisis_periods = get_data_for_date_range(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date\n",
    "    )\n",
    "    \n",
    "    print(\"Data retrieval completed successfully.\")\n",
    "    print(f\"Market data shape: {all_market_data.shape}\")\n",
    "    print(f\"Macro data shape: {all_macro_data.shape}\")\n",
    "    print(f\"Crisis periods: {len(all_crisis_periods)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving all data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that we have retrieved the necessary data, the next steps are to:\n",
    "\n",
    "1. Clean and process the data (Notebook 02_data_cleaning.ipynb)\n",
    "2. Implement VaR models and risk analysis (Notebook 03_var_modeling.ipynb)\n",
    "3. Develop stress testing scenarios (Notebook 05_stress_testing.ipynb)\n",
    "4. Validate the models through backtesting (Notebook 06_backtesting.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
